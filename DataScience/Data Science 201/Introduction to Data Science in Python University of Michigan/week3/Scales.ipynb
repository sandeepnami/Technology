{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's bring in pandas as normal\n",
    "import pandas as pd\n",
    "\n",
    "# Here’s an example. Lets create a dataframe of letter grades in descending order. We can also set an index\n",
    "# value and here we'll just make it some human judgement of how good a student was, like \"excellent\" or \"good\"\n",
    "\n",
    "df=pd.DataFrame(['A+', 'A', 'A-', 'B+', 'B', 'B-', 'C+', 'C', 'C-', 'D+', 'D'],\n",
    "                index=['excellent', 'excellent', 'excellent', 'good', 'good', 'good', \n",
    "                       'ok', 'ok', 'ok', 'poor', 'poor'],\n",
    "               columns=[\"Grades\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, if we check the datatype of this column, we see that it's just an object, since we set string values\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can, however, tell pandas that we want to change the type to category, using the astype() function\n",
    "df[\"Grades\"].astype(\"category\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see now that there are eleven categories, and pandas is aware of what those categories are. More\n",
    "# interesting though is that our data isn't just categorical, but that it's ordered. That is, an A- comes\n",
    "# after a B+, and B comes before a B+. We can tell pandas that the data is ordered by first creating a new\n",
    "# categorical data type with the list of the categories (in order) and the ordered=True flag\n",
    "my_categories=pd.CategoricalDtype(categories=['D', 'D+', 'C-', 'C', 'C+', 'B-', 'B', 'B+', 'A-', 'A', 'A+'], \n",
    "                           ordered=True)\n",
    "# then we can just pass this to the astype() function\n",
    "grades=df[\"Grades\"].astype(my_categories)\n",
    "grades.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we see that pandas is not only aware that there are 11 categories, but it is also aware of the order of\n",
    "# those categoreies. So, what can you do with this? Well because there is an ordering this can help with\n",
    "# comparisons and boolean masking. For instance, if we have a list of our grades and we compare them to a “C”\n",
    "# we see that the lexicographical comparison returns results we were not intending. \n",
    "\n",
    "df[df[\"Grades\"]>\"C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So a C+ is great than a C, but a C- and D certainly are not. However, if we broadcast over the dataframe\n",
    "# which has the type set to an ordered categorical\n",
    "\n",
    "grades[grades>\"C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that the operator works as we would expect. We can then use a certain set of mathematical operators,\n",
    "# like minimum, maximum, etc., on the ordinal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes it is useful to represent categorical values as each being a column with a true or a false as to\n",
    "# whether the category applies. This is especially common in feature extraction, which is a topic in the data\n",
    "# mining course. Variables with a boolean value are typically called dummy variables, and pandas has a built\n",
    "# in function called get_dummies which will convert the values of a single column into multiple columns of\n",
    "# zeros and ones indicating the presence of the dummy variable. I rarely use it, but when I do it's very\n",
    "# handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There’s one more common scale-based operation I’d like to talk about, and that’s on converting a scale from\n",
    "# something that is on the interval or ratio scale, like a numeric grade, into one which is categorical. Now,\n",
    "# this might seem a bit counter intuitive to you, since you are losing information about the value. But it’s\n",
    "# commonly done in a couple of places. For instance, if you are visualizing the frequencies of categories,\n",
    "# this can be an extremely useful approach, and histograms are regularly used with converted interval or ratio\n",
    "# data. In addition, if you’re using a machine learning classification approach on data, you need to be using\n",
    "# categorical data, so reducing dimensionality may be useful just to apply a given technique. Pandas has a\n",
    "# function called cut which takes as an argument some array-like structure like a column of a dataframe or a\n",
    "# series. It also takes a number of bins to be used, and all bins are kept at equal spacing.\n",
    " \n",
    "# Lets go back to our census data for an example. We saw that we could group by state, then aggregate to get a\n",
    "# list of the average county size by state. If we further apply cut to this with, say, ten bins, we can see\n",
    "# the states listed as categoricals using the average county size.\n",
    "\n",
    "# let's bring in numpy\n",
    "import numpy as np\n",
    "\n",
    "# Now we read in our dataset\n",
    "df=pd.read_csv(\"datasets/census.csv\")\n",
    "\n",
    "# And we reduce this to country data\n",
    "df=df[df['SUMLEV']==50]\n",
    "\n",
    "# And for a few groups\n",
    "df=df.set_index('STNAME').groupby(level=0)['CENSUS2010POP'].agg(np.average)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now if we just want to make \"bins\" of each of these, we can use cut()\n",
    "pd.cut(df,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we see that states like alabama and alaska fall into the same category, while california and the\n",
    "# disctrict of columbia fall in a very different category.\n",
    "\n",
    "# Now, cutting is just one way to build categories from your data, and there are many other methods. For\n",
    "# instance, cut gives you interval data, where the spacing between each category is equal sized. But sometimes\n",
    "# you want to form categories based on frequency – you want the number of items in each bin to the be the\n",
    "# same, instead of the spacing between bins. It really depends on what the shape of your data is, and what\n",
    "# you’re planning to do with it."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
